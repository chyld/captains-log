{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for tensorflow devices\n",
    "from tensorflow.python.client import device_lib\n",
    "for d in device_lib.list_local_devices():\n",
    "    print(d.name, d.physical_device_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from keras import optimizers\n",
    "import keras.backend as K\n",
    "from keras.utils import to_categorical, multi_gpu_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.datasets import load_iris\n",
    "from keras.datasets import fashion_mnist, mnist, cifar100\n",
    "import tensorflow as tf\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset generators for test and train\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        rotation_range=20,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset generators for test and train\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'kaggle/dogs-vs-cats/train',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'kaggle/dogs-vs-cats/validation',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all images are scaled to the same size\n",
    "input_shape = (150, 150, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3,3), activation='relu', input_shape=input_shape, name='L0'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(64, (3,3), activation='relu', name='L1'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(128, (3,3), activation='relu', name='L2'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Flatten())         \n",
    "model.add(Dense(512, activation='relu')) \n",
    "model.add(Dropout(0.2))                  \n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making the sequential model run across multiple GPUs\n",
    "opt = optimizers.SGD(lr=0.001)\n",
    "\n",
    "parallel_model = multi_gpu_model(model, 4)\n",
    "parallel_model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "parallel_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of images per batch, and total images\n",
    "train_generator.batch_size, train_generator.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of batches in epoch\n",
    "# added 2x for training to get more random samples\n",
    "train_batches_per_epoch = int(train_generator.samples / train_generator.batch_size) * 2\n",
    "validation_batches_per_epoch = int(validation_generator.samples / validation_generator.batch_size)\n",
    "train_batches_per_epoch, validation_batches_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a batch and its classes\n",
    "batch = train_generator.next()\n",
    "batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are 32, 150x150, 3-channel images in this batch\n",
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show one sample from the batch\n",
    "plt.imshow(batch[0][0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = parallel_model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_batches_per_epoch,\n",
    "        epochs=25,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_batches_per_epoch,\n",
    "        workers=32,\n",
    "        use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
