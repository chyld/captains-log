{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, SpatialDropout1D\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb, reuters\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "with open('data/alice-in-wonderland.txt') as f:\n",
    "    for line in f:\n",
    "        line = line.strip().lower()\n",
    "        if line:\n",
    "            words = words + line.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i--down',\n",
       " 'the',\n",
       " 'rabbit-hole',\n",
       " 'alice',\n",
       " 'was',\n",
       " 'beginning',\n",
       " 'to',\n",
       " 'get',\n",
       " 'very',\n",
       " 'tired']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index = {w:i for i, w in enumerate(set(words))}\n",
    "index_to_word = {v:k for k,v in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 0),\n",
       " ('turkey,', 1),\n",
       " ('party.', 2),\n",
       " ('trouble', 3),\n",
       " ('an', 4),\n",
       " (\"'tis\", 5),\n",
       " ('dead', 6),\n",
       " (\"king's\", 7),\n",
       " ('his', 8),\n",
       " (\"we've\", 9)]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(word_to_index.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, ''),\n",
       " (1, 'turkey,'),\n",
       " (2, 'party.'),\n",
       " (3, 'trouble'),\n",
       " (4, 'an'),\n",
       " (5, \"'tis\"),\n",
       " (6, 'dead'),\n",
       " (7, \"king's\"),\n",
       " (8, 'his'),\n",
       " (9, \"we've\")]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(index_to_word.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "971"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_docs = int(len(words)/10)\n",
    "num_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_generator(docs, offsets):\n",
    "    X_w = []\n",
    "    Y_w = []\n",
    "    for offset in range(offsets):\n",
    "        for doc in range(docs):\n",
    "            x = words[doc*10+offset:doc*10+offset+10]\n",
    "            y = x.pop()\n",
    "            X_w.append(x)\n",
    "            Y_w.append(y)        \n",
    "    return (X_w, Y_w,\n",
    "        np.array([[word_to_index[word] for word in doc] for doc in X_w]), \n",
    "        to_categorical(np.array([word_to_index[word] for word in Y_w])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_w, Y_w, X_i, Y_i = doc_generator(950, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47500"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['i--down',\n",
       "  'the',\n",
       "  'rabbit-hole',\n",
       "  'alice',\n",
       "  'was',\n",
       "  'beginning',\n",
       "  'to',\n",
       "  'get',\n",
       "  'very'],\n",
       " ['of', 'sitting', 'by', 'her', 'sister', 'on', 'the', 'bank,', 'and'],\n",
       " ['having', 'nothing', 'to', 'do.', 'once', 'or', 'twice', 'she', 'had'],\n",
       " ['into', 'the', 'book', 'her', 'sister', 'was', 'reading,', 'but', 'it'],\n",
       " ['no', 'pictures', 'or', 'conversations', 'in', 'it,', '\"and', 'what', 'is'],\n",
       " ['use',\n",
       "  'of',\n",
       "  'a',\n",
       "  'book,\"',\n",
       "  'thought',\n",
       "  'alice,',\n",
       "  '\"without',\n",
       "  'pictures',\n",
       "  'or'],\n",
       " ['so', 'she', 'was', 'considering', 'in', 'her', 'own', 'mind', '(as'],\n",
       " ['as', 'she', 'could,', 'for', 'the', 'day', 'made', 'her', 'feel'],\n",
       " ['sleepy',\n",
       "  'and',\n",
       "  'stupid),',\n",
       "  'whether',\n",
       "  'the',\n",
       "  'pleasure',\n",
       "  'of',\n",
       "  'making',\n",
       "  'a'],\n",
       " ['would', 'be', 'worth', 'the', 'trouble', 'of', 'getting', 'up', 'and']]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_w[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tired',\n",
       " 'of',\n",
       " 'peeped',\n",
       " 'had',\n",
       " 'the',\n",
       " 'conversations?\"',\n",
       " 'well',\n",
       " 'very',\n",
       " 'daisy-chain',\n",
       " 'picking']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_w[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2419, 1346,  728, 1379, 1069, 1196, 1935, 2091,  909],\n",
       "       [1565, 2284, 2300, 1434,  632,  804, 1346,  201, 1895],\n",
       "       [2074,  666, 1935, 2224,  345,  379, 1573, 2257, 1113],\n",
       "       [ 603, 1346,  812, 1434,  632, 1069,  735, 2447, 2340],\n",
       "       [1241, 1463,  379, 2277,  318, 2096, 1490, 1078, 2444],\n",
       "       [ 683, 1565,  283,  528,  537, 1744, 1493, 1463,  379],\n",
       "       [ 320, 2257, 1069, 2073,  318, 1434,  885,  996, 1191],\n",
       "       [ 552, 2257, 1738, 1739, 1346, 1121, 1997, 1434,  717],\n",
       "       [ 482, 1895, 2330, 1238, 1346, 1267, 1565, 1642,  283],\n",
       "       [1754, 1399,  380, 1346,    3, 1565, 1035,  293, 1895]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_i[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_i[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47500, 2464)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2464"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words = len(word_to_index.keys())\n",
    "unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 128)         315392    \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2464)              317856    \n",
      "=================================================================\n",
      "Total params: 764,832\n",
      "Trainable params: 764,832\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(unique_words, 128))\n",
    "model.add(LSTM(128, dropout=0.5, recurrent_dropout=0.5))\n",
    "model.add(Dense(unique_words, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33250 samples, validate on 14250 samples\n",
      "Epoch 1/10\n",
      "33250/33250 [==============================] - 19s 557us/step - loss: 0.0210 - acc: 0.9981 - val_loss: 0.0030 - val_acc: 0.9996\n",
      "Epoch 2/10\n",
      "33250/33250 [==============================] - 21s 619us/step - loss: 0.0030 - acc: 0.9996 - val_loss: 0.0030 - val_acc: 0.9996\n",
      "Epoch 3/10\n",
      "33250/33250 [==============================] - 23s 686us/step - loss: 0.0030 - acc: 0.9996 - val_loss: 0.0030 - val_acc: 0.9996\n",
      "Epoch 4/10\n",
      "33250/33250 [==============================] - 36s 1ms/step - loss: 0.0030 - acc: 0.9996 - val_loss: 0.0030 - val_acc: 0.9996\n",
      "Epoch 5/10\n",
      "33250/33250 [==============================] - 28s 853us/step - loss: 0.0030 - acc: 0.9996 - val_loss: 0.0030 - val_acc: 0.9996\n",
      "Epoch 6/10\n",
      "33250/33250 [==============================] - 24s 725us/step - loss: 0.0031 - acc: 0.9996 - val_loss: 0.0030 - val_acc: 0.9996\n",
      "Epoch 7/10\n",
      "33250/33250 [==============================] - 24s 717us/step - loss: 0.0031 - acc: 0.9996 - val_loss: 0.0030 - val_acc: 0.9996\n",
      "Epoch 8/10\n",
      "33250/33250 [==============================] - 20s 591us/step - loss: 0.0031 - acc: 0.9996 - val_loss: 0.0030 - val_acc: 0.9996\n",
      "Epoch 9/10\n",
      "33250/33250 [==============================] - 21s 629us/step - loss: 0.0031 - acc: 0.9996 - val_loss: 0.0030 - val_acc: 0.9996\n",
      "Epoch 10/10\n",
      "33250/33250 [==============================] - 24s 732us/step - loss: 0.0030 - acc: 0.9996 - val_loss: 0.0030 - val_acc: 0.9996\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_i, Y_i,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1, validation_split=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1346, 1346, 1346])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['turkey,', 'party.', 'trouble', 'an', \"'tis\", 'dead', \"king's\", 'his', \"we've\", 'dear?\"', 'sulky', 'off,']\n",
      "['the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the']\n"
     ]
    }
   ],
   "source": [
    "nums = [1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "preds = model.predict_classes(nums)\n",
    "print([index_to_word[n] for n in nums])\n",
    "print([index_to_word[n] for n in preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'embedding_4_input:0' shape=(?, ?) dtype=float32>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
